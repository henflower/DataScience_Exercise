{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "knitr::opts_chunk$set(echo = TRUE)\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## The problem\n",
                "\n",
                "You will have just worked through an exercise to compare the means of two samples and test the hypothesis that their population means are the same. In that exercise, you were introduced to permutation testing as an alternative approach to understanding significance. The extension invites you to explore yet another approach called the bootstrap. This is an additional section that you may paste at the bottom of your TwoSample_student.Rmd file.\n",
                "\n",
                "## The Bootstrap approach\n",
                "\n",
                "The core idea of the bootstrap is to treat the sample as though it is the population. Doing so, one can imagine resampling the sample from itself. But how do you get a sample of size n from a sample of size n?!? The answer is to sample with replacement.\n",
                "\n",
                "Returning to our original data, let's play with the bootstrap by resampling set_A.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "boot_sample <- group_data$set_A[sample(1:50,replace=TRUE)]\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's compare the mean of this bootstrapped sample to the orginal mean:\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "tibble(mean(boot_sample),mean(group_data$set_A))\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now complete the code block to generate many such bootstrap samples and record each of their means in a list called boot_dist_A.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "n_reps <- 10000\n",
                "boot_dist_A <- rep(0,n_reps)\n",
                "for (i in 1:n_reps)\n",
                "{\n",
                "    boot_sample <- \n",
                "    boot_dist_A[i] <- mean(boot_sample)\n",
                "}\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now plot a histogram of boot_dist_A and include a vertical line at the mean of the original set_A values.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The bootstrap is kind of magical, right? I mean, consider what would happen if you simply changed replace=TRUE to replace=FALSE! (You can try it if you'd like.) \n",
                "\n",
                "What we just have done, without setting out to do so, is use the bootstrap to obtain the sampling distribution of the sample mean of set_A. That gives us some indication of how close the sample mean is likely to be to the population mean. There is a price to pretending that the sample is the population: it ignores the fact that another sample would be different. What that means is that the bootstrap underestimates variation -- it is, in a sense, too optimistic. We'll leave this alone for now, but it is worth mentioning.\n",
                "\n",
                "Let's get back to the original goal of comparing the two groups. How might we use the bootstrap in place of permutations? The reasoning behind the permutation approach was that it created a null scenario in which the values were drawn from a common population. To use the bootstrap for hypothesis testing, we need to do the same. Here's one way to do this:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "combined_set <- c(set_A-mean(set_A),set_B-mean(set_B))\n",
                "boot_combined <- combined_set[sample(1:100,replace=TRUE)]\n",
                "boot_A <- boot_combined[1:50]\n",
                "boot_B <- boot_combined[51:100]\n",
                "tibble(boot_A,boot_B)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Explain in the block below what this code is doing. If you are feeling adventurous, you can add a second code block to plot the two histograms side by side.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now that we know how to generate null samples, we can once again compute our t statistic:\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "boot_t_test_results <- t.test(boot_A,boot_B,var.equal=T)\n",
                "str(boot_t_test_results)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "But what we really want is to do this many times. If you've made it this far, you can write this code on your own. Generate 10000 bootstrap samples and run the t test for each, using the variable boot_samp_dist to record all of the t statistics.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Next make a visual comparison of our bootstrap and permutation results. To do so, produce the histograms of both sampling distributions (boot_samp_dist and samp_dist) side by side (using facet_wrap), with a different colour for each.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Comment on what you observe. Based on your plot, do you think that the bootstrap p-value will be similar to that obtained by permutation?\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Finally, confirm this by computing the bootstrap p-value in the code block below:\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "boot_pvalue <- \n",
                "boot_pvalue\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "\n"
            ]
        }
    ],
    "metadata": {
        "anaconda-cloud": "",
        "kernelspec": {
            "display_name": "R",
            "langauge": "R",
            "name": "ir"
        },
        "language_info": {
            "codemirror_mode": "r",
            "file_extension": ".r",
            "mimetype": "text/x-r-source",
            "name": "R",
            "pygments_lexer": "r",
            "version": "3.4.1"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}
